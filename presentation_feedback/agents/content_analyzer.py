"""å†…å®¹åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - Amazon Nova Liteä½¿ç”¨."""

import os
from strands import Agent
from strands.models import BedrockModel
from typing import Dict


# ã‚ªãƒ¬ã‚´ãƒ³ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆus-west-2ï¼‰ã®Nova Lite
AWS_REGION = "us-west-2"
NOVA_LITE_MODEL_ID = "us.amazon.nova-lite-v1:0"

SYSTEM_PROMPT = """ã‚ãªãŸã¯ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å†…å®¹ã®åˆ†æå°‚é–€å®¶ã§ã™ã€‚
æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€ç™ºè¡¨ã®æ§‹æˆã¨è¨€è‘‰é£ã„ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

åˆ†æè¦³ç‚¹:
1. æ§‹æˆ: ã‚¤ãƒ³ãƒˆãƒ­â†’æœ¬é¡Œâ†’ã¾ã¨ã‚ã®æµã‚ŒãŒã‚ã‚‹ã‹
   - ã‚¤ãƒ³ãƒˆãƒ­: æœ€åˆã®10%ä»¥å†…ã«å°å…¥ãƒ»ãƒ†ãƒ¼ãƒç´¹ä»‹ãŒã‚ã‚‹ã‹
   - ã¾ã¨ã‚: æœ€å¾Œã®10%ã«çµè«–ãƒ»ç·æ‹¬ãŒã‚ã‚‹ã‹
2. è«–ç†æ€§: è©±ã®ç¹‹ãŒã‚ŠãŒè‡ªç„¶ã‹ã€ãƒˆãƒ”ãƒƒã‚¯é·ç§»ãŒã‚¹ãƒ ãƒ¼ã‚ºã‹
3. è¨€è‘‰é£ã„: ã‚ã‹ã‚Šã‚„ã™ã„è¡¨ç¾ã‹ã€å°‚é–€ç”¨èªã¯é©åˆ‡ã‹
4. æ™‚é–“é…åˆ†: ã‚¤ãƒ³ãƒˆãƒ­ãƒ»æœ¬é¡Œãƒ»ã¾ã¨ã‚ã®ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã‚‹ã‹

ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®ã€Œä¼ã‚ã‚Šã‚„ã™ã•ã€ã‚’é‡è¦–ã—ã¦è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{
  "structure": {
    "has_intro": true/false,
    "has_conclusion": true/false,
    "feedback": "æ§‹æˆã«é–¢ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"
  },
  "language": {
    "clarity": "high/medium/low",
    "feedback": "è¨€è‘‰é£ã„ã«é–¢ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯"
  },
  "strengths": ["å¼·ã¿1", "å¼·ã¿2", ...],
  "improvements": ["æ”¹å–„ç‚¹1", "æ”¹å–„ç‚¹2", ...]
}
"""


class ContentAnalyzer:
    """å†…å®¹åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ."""

    def __init__(self):
        """åˆæœŸåŒ–."""
        model = BedrockModel(model_id=NOVA_LITE_MODEL_ID, region_name=AWS_REGION)
        self.agent = Agent(model=model, system_prompt=SYSTEM_PROMPT)

    def analyze_content(self, transcription: Dict) -> Dict:
        """
        ãƒ—ãƒ¬ã‚¼ãƒ³å†…å®¹ã‚’åˆ†æ.

        Args:
            transcription: æ›¸ãèµ·ã“ã—çµæœ

        Returns:
            dict: åˆ†æçµæœ
                {
                    "structure": {...},
                    "language": {...},
                    "strengths": [...],
                    "improvements": [...],
                    "usage": {
                        "input_tokens": int,
                        "output_tokens": int
                    }
                }
        """
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""
ä»¥ä¸‹ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ›¸ãèµ·ã“ã—ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ç·æ™‚é–“ã€‘
{transcription['duration']:.1f}ç§’ ({transcription['duration'] / 60:.1f}åˆ†)

ã€æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã€‘
{transcription['text']}

ä¸Šè¨˜ã®ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å†…å®¹ã«ã¤ã„ã¦ã€æ§‹æˆãƒ»è¨€è‘‰é£ã„ãƒ»è«–ç†æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
"""

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
        print("ğŸ“ å†…å®¹ã‚’åˆ†æä¸­...")
        result = self.agent(prompt)

        # çµæœã‚’ãƒ‘ãƒ¼ã‚¹
        import json
        try:
            analysis = json.loads(result.output)
        except json.JSONDecodeError:
            # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            analysis = {
                "structure": {
                    "has_intro": True,
                    "has_conclusion": True,
                    "feedback": result.output[:200]
                },
                "language": {
                    "clarity": "medium",
                    "feedback": ""
                },
                "strengths": [],
                "improvements": []
            }

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¿½åŠ 
        analysis["usage"] = {
            "input_tokens": result.usage.input_tokens,
            "output_tokens": result.usage.output_tokens
        }

        print(f"âœ“ å†…å®¹åˆ†æå®Œäº† (å…¥åŠ›: {result.usage.input_tokens}, å‡ºåŠ›: {result.usage.output_tokens} ãƒˆãƒ¼ã‚¯ãƒ³)")

        return analysis


def create_content_analyzer() -> ContentAnalyzer:
    """
    å†…å®¹åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ.

    Returns:
        ContentAnalyzer: å†…å®¹åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    return ContentAnalyzer()
