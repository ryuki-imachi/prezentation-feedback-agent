"""éŸ³å£°ç‰¹å¾´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - Amazon Nova Liteä½¿ç”¨."""

import os
from strands import Agent
from strands.models import BedrockModel
from typing import Dict


# ã‚ªãƒ¬ã‚´ãƒ³ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆus-west-2ï¼‰ã®Nova Lite
AWS_REGION = "us-west-2"
NOVA_LITE_MODEL_ID = "us.amazon.nova-lite-v1:0"

SYSTEM_PROMPT = """ã‚ãªãŸã¯éŸ³å£°ç‰¹å¾´åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸæ›¸ãèµ·ã“ã—ãƒ‡ãƒ¼ã‚¿ã¨éŸ³å£°ç‰¹å¾´é‡ã‹ã‚‰ã€ç™ºè¡¨è€…ã®è©±ã—æ–¹ã«ã¤ã„ã¦åˆ†æã—ã¦ãã ã•ã„ã€‚

åˆ†æè¦³ç‚¹:
1. è©±ã™ã‚¹ãƒ”ãƒ¼ãƒ‰: é€Ÿã™ããšé…ã™ããªã„é©åˆ‡ãªãƒšãƒ¼ã‚¹ã‹ï¼ˆæ—¥æœ¬èª: 300-350æ–‡å­—/åˆ†ãŒç›®å®‰ï¼‰
2. ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ä¸è¦ãªå£ç™–ï¼ˆã€Œãˆãƒ¼ã€ã€Œã‚ã®ãƒ¼ã€ãªã©ï¼‰ãŒå¤šããªã„ã‹
3. é–“ï¼ˆãƒãƒ¼ã‚ºï¼‰: é©åˆ‡ãªé–“ãŒå–ã‚Œã¦ã„ã‚‹ã‹

ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã¯å…·ä½“çš„ã‹ã¤å»ºè¨­çš„ã«ã€‚æ•°å€¤çš„ãªæ ¹æ‹ ã‚‚ç¤ºã—ã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONå½¢å¼ã§ä»¥ä¸‹ã®æ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„:
{
  "feedback": "éŸ³å£°ç‰¹å¾´ã«é–¢ã™ã‚‹ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ï¼ˆæ®µè½å½¢å¼ï¼‰",
  "strengths": ["å¼·ã¿1", "å¼·ã¿2", ...],
  "improvements": ["æ”¹å–„ç‚¹1", "æ”¹å–„ç‚¹2", ...]
}
"""


class SpeechAnalyzer:
    """éŸ³å£°ç‰¹å¾´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ."""

    def __init__(self):
        """åˆæœŸåŒ–."""
        model = BedrockModel(model_id=NOVA_LITE_MODEL_ID, region_name=AWS_REGION)
        self.agent = Agent(model=model, system_prompt=SYSTEM_PROMPT)

    def analyze_speech(self, transcription: Dict, audio_features: Dict) -> Dict:
        """
        éŸ³å£°ç‰¹å¾´ã‚’åˆ†æ.

        Args:
            transcription: æ›¸ãèµ·ã“ã—çµæœ
            audio_features: éŸ³å£°ç‰¹å¾´é‡ï¼ˆè©±é€Ÿã€ãƒãƒ¼ã‚ºç­‰ï¼‰

        Returns:
            dict: åˆ†æçµæœ
                {
                    "feedback": "åˆ†æçµæœãƒ†ã‚­ã‚¹ãƒˆ",
                    "strengths": [...],
                    "improvements": [...],
                    "usage": {
                        "input_tokens": int,
                        "output_tokens": int
                    }
                }
        """
        # ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ•´å½¢
        filler_words = audio_features.get('filler_words', {})
        filler_summary = "\n".join(
            [f"  - {word}: {data['count']}å›" for word, data in filler_words.items()]
        ) if filler_words else "  ãªã—"

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        prompt = f"""
ä»¥ä¸‹ã®éŸ³å£°ç‰¹å¾´é‡ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€éŸ³å£°ç‰¹å¾´é‡ã€‘
- è©±é€Ÿ: {audio_features.get('speaking_rate', 0):.1f} æ–‡å­—/åˆ†
- ãƒ•ã‚£ãƒ©ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
{filler_summary}
- ãƒãƒ¼ã‚ºçµ±è¨ˆ:
  - ç·ãƒãƒ¼ã‚ºæ•°: {audio_features.get('pauses', {}).get('total', 0)}
  - å¹³å‡ãƒãƒ¼ã‚ºæ™‚é–“: {audio_features.get('pauses', {}).get('avg_duration', 0):.2f}ç§’
  - é•·ã™ãã‚‹ãƒãƒ¼ã‚º: {len(audio_features.get('pauses', {}).get('long_pauses', []))}å›

ã€æ›¸ãèµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæŠœç²‹ï¼‰ã€‘
{transcription['text'][:500]}...

ä¸Šè¨˜ã®æƒ…å ±ã‚’ã‚‚ã¨ã«ã€éŸ³å£°ç‰¹å¾´ã«ã¤ã„ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
"""

        # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œ
        print("ğŸ” éŸ³å£°ç‰¹å¾´ã‚’åˆ†æä¸­...")
        result = self.agent.run(prompt)

        # çµæœã‚’ãƒ‘ãƒ¼ã‚¹
        import json
        try:
            analysis = json.loads(result.output)
        except json.JSONDecodeError:
            # JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            analysis = {
                "feedback": result.output,
                "strengths": [],
                "improvements": []
            }

        # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’è¿½åŠ 
        analysis["usage"] = {
            "input_tokens": result.usage.input_tokens,
            "output_tokens": result.usage.output_tokens
        }

        print(f"âœ“ éŸ³å£°ç‰¹å¾´åˆ†æå®Œäº† (å…¥åŠ›: {result.usage.input_tokens}, å‡ºåŠ›: {result.usage.output_tokens} ãƒˆãƒ¼ã‚¯ãƒ³)")

        return analysis


def create_speech_analyzer() -> SpeechAnalyzer:
    """
    éŸ³å£°ç‰¹å¾´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆ.

    Returns:
        SpeechAnalyzer: éŸ³å£°ç‰¹å¾´åˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
    """
    return SpeechAnalyzer()


